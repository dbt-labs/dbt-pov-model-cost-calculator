name: Integration Tests

# This workflow tests the dbt_pov_model_cost_calculator package against:
# - 3 adapters: snowflake, databricks, bigquery
# - 2 dbt commands: dbt, dbtf
# Total: 6 test combinations (3 adapters Ã— 2 commands)

on:
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    name: Test ${{ matrix.dbt-command }} on ${{ matrix.adapter }} ${{ matrix.cluster_type }}
    strategy:
      matrix:
        adapter: [snowflake, databricks, bigquery, redshift]
        dbt-command: [dbt, dbtf]
        cluster_type: ['', provisioned, serverless]
        exclude:
          - adapter: snowflake
            cluster_type: provisioned
          - adapter: snowflake
            cluster_type: serverless

          - adapter: databricks
            cluster_type: provisioned
          - adapter: databricks
            cluster_type: serverless

          - adapter: bigquery
            cluster_type: provisioned
          - adapter: bigquery
            cluster_type: serverless

          - adapter: redshift
            cluster_type: ''

      fail-fast: false

    env:
      TARGET: "${{ matrix.adapter == 'redshift' && format('{0}_{1}', matrix.adapter, matrix.cluster_type) || matrix.adapter }}"

      # Snowflake Environment Variables
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      DBT_ENV_SECRET_SNOWFLAKE_PASSWORD: ${{ secrets.DBT_ENV_SECRET_SNOWFLAKE_PASSWORD }}
      SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
      SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}

      # Databricks Environment Variables
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_HTTP_PATH: ${{ secrets.DATABRICKS_HTTP_PATH }}
      DBT_ENV_SECRET_DATABRICKS_TOKEN: ${{ secrets.DBT_ENV_SECRET_DATABRICKS_TOKEN }}
      DATABRICKS_CATALOG: ${{ secrets.DATABRICKS_CATALOG }}
      DATABRICKS_SCHEMA: ${{ secrets.DATABRICKS_SCHEMA }}

      # BigQuery Environment Variables
      BIGQUERY_PROJECT: ${{ secrets.BIGQUERY_PROJECT }}
      BIGQUERY_DATASET: ${{ secrets.BIGQUERY_DATASET }}
      DBT_ENV_SECRET_BIGQUERY_PRIVATE_KEY_ID: ${{ secrets.DBT_ENV_SECRET_BIGQUERY_PRIVATE_KEY_ID }}
      DBT_ENV_SECRET_BIGQUERY_PRIVATE_KEY: ${{ secrets.DBT_ENV_SECRET_BIGQUERY_PRIVATE_KEY }}
      BIGQUERY_CLIENT_EMAIL: ${{ secrets.BIGQUERY_CLIENT_EMAIL }}
      BIGQUERY_CLIENT_ID: ${{ secrets.BIGQUERY_CLIENT_ID }}
      BIGQUERY_CLIENT_X509_CERT_URL: ${{ secrets.BIGQUERY_CLIENT_X509_CERT_URL }}
      BIGQUERY_LOCATION: ${{ secrets.BIGQUERY_LOCATION }}

      # Redshift Provisioned Environment Variables
      REDSHIFT_PROVISIONED_HOST: ${{ secrets.REDSHIFT_PROVISIONED_HOST }}
      REDSHIFT_PROVISIONED_DBNAME: ${{ secrets.REDSHIFT_PROVISIONED_DBNAME }}
      REDSHIFT_PROVISIONED_SCHEMA: ${{ secrets.REDSHIFT_PROVISIONED_SCHEMA }}
      REDSHIFT_PROVISIONED_USER: ${{ secrets.REDSHIFT_PROVISIONED_USER }}
      DBT_ENV_SECRET_REDSHIFT_PROVISIONED_PASSWORD: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PROVISIONED_PASSWORD }}

      # Redshift Serverless Environment Variables
      REDSHIFT_SERVERLESS_HOST: ${{ secrets.REDSHIFT_SERVERLESS_HOST }}
      REDSHIFT_SERVERLESS_DBNAME: ${{ secrets.REDSHIFT_SERVERLESS_DBNAME }}
      REDSHIFT_SERVERLESS_SCHEMA: ${{ secrets.REDSHIFT_SERVERLESS_SCHEMA }}
      REDSHIFT_SERVERLESS_USER: ${{ secrets.REDSHIFT_SERVERLESS_USER }}
      DBT_ENV_SECRET_REDSHIFT_SERVERLESS_PASSWORD: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_SERVERLESS_PASSWORD }}

      # test environment variables
      DBT_CLOUD_RUN_REASON: "test' single quote and special characters: #$%^&*()_+-=[]{};:,.<>?`. literal double-quote: \", literal backslash + single quote: \\', literal backslash: \\, literal backslash + backslash: \\\\ and finally $'\n'"

    steps:
      - name: Checkout Repository
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@7f4fc3e22c37d6ff65e88745f38bd3157c663f7c # actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dbt and Adapters
        run: |
          if [ "${{ matrix.dbt-command }}" = "dbtf" ]; then
            # Install dbtf - create alias for dbtf command
            sudo apt-get install -y curl
            curl -fsSL https://public.cdn.getdbt.com/fs/install/install.sh | sh -s -- --update --version dev
            # Create dbtf alias that points to dbt
            echo '#!/bin/bash' > /usr/local/bin/dbtf
            echo 'exec dbt "$@"' >> /usr/local/bin/dbtf
            chmod +x /usr/local/bin/dbtf
            echo "Created dbtf alias pointing to dbt"
          else
            # Install regular dbt
            pip install dbt-core dbt-${{ matrix.adapter }}
          fi

      - name: Show dbt Command Info
        run: |
          echo "Using dbt command: ${{ matrix.dbt-command }}"
          echo "Testing adapter: ${TARGET}"
          which ${{ matrix.dbt-command }} || echo "Command not found in PATH"

      - name: Install Dependencies
        run: |
          ${{ matrix.dbt-command }} deps --target ${TARGET} --profiles-dir integration_tests --project-dir integration_tests/test_project ${EXTRA_DBT_ARGS}

      - name: Debug Connection
        run: |
          ${{ matrix.dbt-command }} debug --target ${TARGET} --profiles-dir integration_tests --project-dir integration_tests/test_project ${EXTRA_DBT_ARGS}

      - name: Run dbt Compile
        run: |
          EXTRA_DBT_ARGS="{\"enabled_targets\": [\"${{ matrix.adapter }}\"]}"
          if [ "${TARGET}" = "redshift_serverless" ]; then
              EXTRA_DBT_ARGS="{\"is_serverless_redshift\":true, \"enabled_targets\": [\"${{ matrix.adapter }}\"]}"
          fi
          echo "With additional args: ${EXTRA_DBT_ARGS}"
          ${{ matrix.dbt-command }} compile --target ${TARGET} --profiles-dir integration_tests \
          --project-dir integration_tests/test_project --vars "$EXTRA_DBT_ARGS"

      - name: Run dbt Build
        run: |
          EXTRA_DBT_ARGS='--vars "{\"enabled_targets\": [\"${{ matrix.adapter }}\"]}"'
          if [ "${TARGET}" = "redshift_serverless" ]; then
              EXTRA_DBT_ARGS='--vars "{\"is_serverless_redshift\":true, \"enabled_targets\": [\"${{ matrix.adapter }}\"]}" --debug'
          fi
          echo "With additional args: ${EXTRA_DBT_ARGS}"
          ${{ matrix.dbt-command }} build --target ${TARGET} --profiles-dir integration_tests \
          --project-dir integration_tests/test_project \
          --full-refresh --vars "$EXTRA_DBT_ARGS"

      # - name: Verify Artifact Table
      #   run: |
      #     ${{ matrix.dbt-command }} run-operation query --args '{sql: "select count(*) as execution_count from {{ var(\"artifact_table\", \"dbt_model_executions\") }} where model_name in (\"test_basic_model\", \"test_view_model\", \"test_incremental_model\") and status = \"success\""}' --target ${{ matrix.adapter }} --profiles-dir integration_tests --project-dir integration_tests/test_project

      # - name: Clean Up
      #   if: always()
      #   run: |
      #     ${{ matrix.dbt-command }} run-operation query --args '{sql: "drop table if exists {{ var(\"artifact_table\", \"dbt_model_executions\") }}"}' --target ${{ matrix.adapter }} --profiles-dir integration_tests --project-dir integration_tests/test_project || true
      #     ${{ matrix.dbt-command }} run-operation query --args '{sql: "drop table if exists test_basic_model"}' --target ${{ matrix.adapter }} --profiles-dir integration_tests --project-dir integration_tests/test_project || true
      #     ${{ matrix.dbt-command }} run-operation query --args '{sql: "drop view if exists test_view_model"}' --target ${{ matrix.adapter }} --profiles-dir integration_tests --project-dir integration_tests/test_project || true
      #     ${{ matrix.dbt-command }} run-operation query --args '{sql: "drop table if exists test_incremental_model"}' --target ${{ matrix.adapter }} --profiles-dir integration_tests --project-dir integration_tests/test_project || true
